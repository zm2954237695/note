##### HashMap的结构

Hashmap的底层是哈希表，而在Java中哈希表是用数组+链表实现的。每一个数组的节点称为bucket桶。但桶中有多个元素时就以链表的方式进行存储。当添加元素时，通过key的hash算法计算出hash值。然后通过hash值(对数组长度取模)映射出存在哪个桶里。如果桶中没有元素则添加成功。如果有元素就代表着散列冲突。比较已经存在的元素的hashCode和新插入的元素的hashCode是否相同，如果没有相同的则添加成功(情况1).如果某个元素的hashCode和插入元素的hashCode相同,则调用key的equals方法继续比较，如果为true则新的值覆盖已经存在的值,否则就插入链表中(情况2).对于情况1和情况2，在jdk1.7中是将新的元素添加到原来的头节点(头插法)。jdk1.8是将新的元素添加到链表末尾节点(尾插法).在jdk1.8中做了一个优化，当桶中元素(链表长度)大于8且数组长度>64则转化为红黑树，如果需要扩容再进行扩容。数组长度小于64会先进行扩容。

jdk1.7及之前: （Entry)数组+链表

jdk1.8：(Node)数组+链表/红黑树

##### 负载因子为0.75的原因

负载因子是扩容机制的一个阈值,假如数组容量为16，当容量到达了0.75*16=12,就会进行扩容.

如果负载因子选择较大(1.0):

我们知道数据一开始是存在数组里的，当发生了哈希冲突时，就会在该数据节点上生出一个链表。当链表长度达到一定长度时，就被转化为红黑树。

当负载因子为1.0时，意味着，只有当数组的8个位置都全部填充时，才会进行扩容。这就带来很大问题，哈希冲突是不可避免。(极端情况下有可能某个桶一直没有节点，而某个桶的链表长度过大，查询性能会降低).

总之: 当负载因子较大时，意味着会出现较大的hash冲突，底层红黑树会变得异常复杂。对查询效率极其不利。这种情况就是牺牲了时间来保证空间利用率。

如果负载因子选择较小(0.5):

当负载因子为0.5，意味着，当数组中元素达到一半就会进行扩容，填充元素少了，hash冲突也会减少，那么底层的链表长度或者红黑树的高度就会降低，查询效率会提高。

但是，此时空间利用率大大降低，原本存储1M的数据，现在就意味着需要2M的空间。

总之: 当负载因子较大时，虽然时间效率提升了，但空间利用率也降低了。

选择负载0.75是空间利用率和时间效率折中的结果。此时空间利用率还比较高，而且避免了很多的hash冲突。使得底层的链表长度或红黑树高度还比较低，提高了查询性能。

 ##### HashMap什么时候进行扩容，为什么要扩容

当hashMap的元素个数超过数组长度*loadFactor时，会进行扩容。(如当数组长度为16，loadFactor为0.75时，元素个数超过12就会进行扩容。)数组长度扩容为原来的2倍.

当HashMap元素越来越多时，碰撞的几率越来越大，所以为了提高查询的效率，需要对HashMap进行扩容。

##### 多线程put操作引起的数据丢失

比如有两个线程A和B，A希望插入一个key-value对到hashmap中。首先计算记录所要落到桶的索引坐标，然后获取到该桶里面的链表头节点。此时A的时间片用完了，而线程B被得到调度，和线程A一样执行，不过线程B成功将记录插到桶里面。假设线程A插入的记录计算出来的桶索引和线程B计算出来的一样，当线程A再次被调度执行时，它依然持有过期的链表头但它对此却一无所知，还是对该位置插入了数据，这样线程B插入的记录就凭空消失了，造成了数据不一致的情况。

##### 多线程get操作(resize)的线程安全问题

resize过程，就是容量扩大为原先容量2倍，并把当前Entry[] table数组的全部元素转移到新的table中。其他transfer函数就是实现这个功能。这个transfer的过程在并发环境下会发生错误，导致数组链表中的链表形成循环链表，在后面的get操作时e = e.next操作无限循环，Infinite Loop出现。

##### ConcurrentHashMap

JDK1.7

ConcurrentHashMap的数据结构是由一个Segmengt数组和多个HashEntry组成。

##### 初始化

ConcurrentHashMap的初始化通过位运算来初始化Segment的大小

Segment的大小最大为为65536(1<<16),没有指定concurrencyLevel，Segment的大小默认为16

```java
int size =1;
while(size < concurrencyLevel) {
++a;
size <<=1;
}    
```

每一个Segment元素下的HashEntry的初始化也是通过位运算计算。HashEntry的最小容量为2.

##### put操作

Segment实现了ReentrantLock,也就具有锁的功能。当执行put方法时，会进行第一次key的Hash来定位Segment的位置，如果Segment还没初始化，使用CAS操作进行赋值，然后进行第二次Hash，找到相应的HashEntry的位置，将数据插入指定的HashEntry位置(链表的尾端)，这里通过继承了ReentrantLock的tryLock方法获取锁，如果获取成功就插入相应位置，如果已经有线程获取该Segment的锁，当前线程会以自选的方式去继续调用tryLock方法来获取锁，超过指定次数就挂起，等待唤醒。

##### get操作

ConcurrentHashmap的get操作和HashMap类似，只是ConcurrentHashMap第一次需要经过一次hash定位到Segment的位置，然后再hash定位到指定的HashEntry，遍历该HashEntry下的链表进行对比，成功就返回，不成功就返回null



